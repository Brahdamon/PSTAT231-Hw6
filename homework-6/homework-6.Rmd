---
title: "Homework 6"
author: "PSTAT 131/231"
output:
    html_document:
      toc: true
      toc_float: true
      code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE,
                      warning = FALSE)
```

## Tree-Based Models

For this assignment, we will continue working with the file `"pokemon.csv"`, found in `/data`. The file is from Kaggle: <https://www.kaggle.com/abcsds/pokemon>.

The [Pokémon](https://www.pokemon.com/us/) franchise encompasses video games, TV shows, movies, books, and a card game. This data set was drawn from the video game series and contains statistics about 721 Pokémon, or "pocket monsters." In Pokémon games, the user plays as a trainer who collects, trades, and battles Pokémon to (a) collect all the Pokémon and (b) become the champion Pokémon trainer.

Each Pokémon has a [primary type](https://bulbapedia.bulbagarden.net/wiki/Type) (some even have secondary types). Based on their type, a Pokémon is strong against some types, and vulnerable to others. (Think rock, paper, scissors.) A Fire-type Pokémon, for example, is vulnerable to Water-type Pokémon, but strong against Grass-type.

![Fig 1. Houndoom, a Dark/Fire-type canine Pokémon from Generation II.](images/houndoom.jpg){width="200"}

The goal of this assignment is to build a statistical learning model that can predict the **primary type** of a Pokémon based on its generation, legendary status, and six battle statistics.

**Note: Fitting ensemble tree-based models can take a little while to run. Consider running your models outside of the .Rmd, storing the results, and loading them in your .Rmd to minimize time to knit.**

### Exercise 1

Read in the data and set things up as in Homework 5:

- Use `clean_names()`
- Filter out the rarer Pokémon types
- Convert `type_1` and `legendary` to factors

```{r}
library(janitor)
library(tidyverse)
library(tidymodels)
library(corrr)
library(corrplot)

tidymodels_prefer()

data <- read_csv("data/Pokemon.csv")
data_cln <- clean_names(data)

typeCount <- table(data_cln$type_1)
typesToFilter <- c("Bug", "Fire", "Grass", "Normal", "Water", "Psychic")

filteredData <- filter(data_cln, type_1 %in% typesToFilter)

filteredData$type_1 <- as.factor(filteredData$type_1)
filteredData$legendary <- as.factor(filteredData$legendary)

head(data)
head(data_cln)
```

Do an initial split of the data; you can choose the percentage for splitting. Stratify on the outcome variable.

```{r}
pokeSplit <- initial_split(filteredData,
                           prop = 0.8,
                           strata = type_1)

pokeTrain <- training(pokeSplit)
pokeTest <- testing(pokeSplit)
```


Fold the training set using *v*-fold cross-validation, with `v = 5`. Stratify on the outcome variable.

```{r}

pokeFolds <- vfold_cv(pokeTrain,
                      v = 5,
                      strata = type_1)
```

Set up a recipe to predict `type_1` with `legendary`, `generation`, `sp_atk`, `attack`, `speed`, `defense`, `hp`, and `sp_def`:

- Dummy-code `legendary` and `generation`;
- Center and scale all predictors.

```{r}
pokeRecipe <- recipe(type_1 ~ 
                       legendary +
                       generation +
                       sp_atk +
                       attack +
                       speed +
                       defense +
                       sp_def +
                       hp, 
                     data = pokeTrain) %>%
  step_dummy(legendary, generation) %>%
  step_normalize(all_numeric_predictors())
```

### Exercise 2

Create a correlation matrix of the training set, using the `corrplot` package. *Note: You can choose how to handle the continuous variables for this plot; justify your decision(s).*

****

```{r}
head(filteredData)
names(filteredData)

corrData <- filteredData %>%
  select(is.numeric) %>%
  select(-c(generation)) %>%
  cor() %>%
  corrplot(type = 'full', diag = TRUE, 
           method = 'color')

# rplot(corrData)
```

What relationships, if any, do you notice? Do these relationships make sense to you?

**All predictors are positively correlated with the other predictors. This makes sense, because the more powerful pokemon would have better overall statistics and values for their attributes.**

### Exercise 3

First, set up a decision tree model and workflow. Tune the `cost_complexity` hyperparameter. Use the same levels we used in Lab 7 -- that is, `range = c(-3, -1)`. Specify that the metric we want to optimize is `roc_auc`. 


```{r}
library(tidyverse)
library(tidymodels)
library(ISLR)
library(rpart.plot)
library(vip)
library(janitor)
library(randomForest)
library(xgboost)

set.seed(22)

tree_spec <- decision_tree() %>%
  set_engine("rpart")

class_tree_spec <- tree_spec %>%
  set_mode("classification")


class_tree_wf <- workflow() %>%
add_model(class_tree_spec %>% set_args(cost_complexity = tune())) %>%
  add_recipe(pokeRecipe)


param_grid <- grid_regular(cost_complexity(range = c(-3, -1)), levels = 10)

tune_res <- tune_grid(
  class_tree_wf, 
  resamples = pokeFolds, 
  grid = param_grid, 
  metrics = metric_set(roc_auc)
)

autoplot(tune_res)
```

Print an `autoplot()` of the results. What do you observe? Does a single decision tree perform better with a smaller or larger complexity penalty?

**The graph of roc_auc stays relatively constant for cost-complexity parameter values betwixt 0.001 and 0.01. It increases substantially where the cost-complexity parameter value is just greater than 0.01, then declines sharply. A single decision tree performs better in general with a smaller cost-complexity penalty.**

### Exercise 4

What is the `roc_auc` of your best-performing pruned decision tree on the folds? *Hint: Use `collect_metrics()` and `arrange()`.*

**The roc_auc of our best-performing pruned decision tree on the folds is 0.6387**
```{r}
arrange(collect_metrics(tune_res), desc(mean))
```


### Exercise 5

Using `rpart.plot`, fit and visualize your best-performing pruned decision tree with the *training* set.

```{r}
best_complexity <- select_best(tune_res)

class_tree_final <- finalize_workflow(class_tree_wf, best_complexity)

class_tree_final_fit <- fit(class_tree_final, data = pokeTrain)

class_tree_final_fit %>%
  extract_fit_engine() %>%
  rpart.plot()


# class_tree_fit <- class_tree_spec %>%
#   fit(type_1 ~ . ,data = pokeTrain)
# 
# class_tree_fit %>%
#   extract_fit_engine() %>%
#   rpart.plot()
```

### Exercise 5

Now set up a random forest model and workflow. Use the `ranger` engine and set `importance = "impurity"`. Tune `mtry`, `trees`, and `min_n`. Using the documentation for `rand_forest()`, explain in your own words what each of these hyperparameters represent.

```{r}
rf_spec <- rand_forest() %>%
  set_engine("ranger", importance = "impurity") %>%
  set_mode("classification")


rf_wf <- workflow() %>%
  add_model(rf_spec %>% set_args(mtry = tune(), trees = tune(), min_n = tune())) %>%
  add_recipe(pokeRecipe)
```

**The parameter "trees" codes the number of trees to be fit to the model. The parameter "mtry" specifies the number of predictors that will be considered at each node of the tree medels, and "min_n" gives a lower limit for the number of data points present at a node required for the node to be split again.**

Create a regular grid with 8 levels each. You can choose plausible ranges for each hyperparameter. Note that `mtry` should not be smaller than 1 or larger than 8. **Explain why not. What type of model would `mtry = 8` represent?**

**mtry is the number of predictors to be considered in a split. IF mtry was less than 1, there would be no criterion on which to split. mtry could not be greater than 8 because there are only 8 possible criteria on which to split. If mtry = 8, then we are looking at a bagging random forest model.**

```{r}

param_grid <- grid_regular(mtry(range = c(1,8)),
                           min_n(range = c(2,20)),
                           trees(range = c(10,300)), levels = 8)

```



### Exercise 6

Specify `roc_auc` as a metric. Tune the model and print an `autoplot()` of the results. What do you observe? What values of the hyperparameters seem to yield the best performance?

**It seems that on average, the more trees there are the better, a minimal node size between 7 and 17, and 2-4 randomly selected predictors seem to result in the best performance**

```{r}

rf_tune_res <- tune_grid(
  rf_wf, 
  resamples = pokeFolds, 
  grid = param_grid, 
  metrics = metric_set(roc_auc)
)

autoplot(rf_tune_res)

```

### Exercise 7

What is the `roc_auc` of your best-performing random forest model on the folds? *Hint: Use `collect_metrics()` and `arrange()`.*

**The roc_auc of our best-performing random forest model on the folds is 0.73136**

```{r}
arrange(collect_metrics(rf_tune_res), desc(mean))
```

### Exercise 8

Create a variable importance plot, using `vip()`, with your best-performing random forest model fit on the *training* set.

Which variables were most useful? Which were least useful? Are these results what you expected, or not?

**The predictors sp_atk and attack were the two most useful variables for predicting the primary pokemon type. The worst three variables for the same prediction were legendary status, the generation from which the pokemon came, and defense. The fact that generation and legendary status were the least important predictors do not come as a surprise. There are are a variety of types that the different legendary pokemon take, and I wouldn't expect substantially more of certain types to be present in any one generation**

```{r}

best_params <- select_best(rf_tune_res)
rf_final <- finalize_workflow(rf_wf, best_params)
rf_final_fit <- fit(rf_final, data = pokeTrain)

rf_final_fit%>%
  pull_workflow_fit()%>%
  vip()
```

### Exercise 9

Finally, set up a boosted tree model and workflow. Use the `xgboost` engine. Tune `trees`. Create a regular grid with 10 levels; let `trees` range from 10 to 2000. Specify `roc_auc` and again print an `autoplot()` of the results. 

```{r}
boost_spec <- boost_tree() %>%
  set_engine("xgboost") %>%
  set_mode("classification")

boost_wf <- workflow() %>%
  add_model(boost_spec %>% set_args(trees = tune())) %>%
  add_recipe(pokeRecipe)
  

trees_grid <- grid_regular(trees(range = c(10,2000)), levels = 10)


boosted_tune_res <- tune_grid(
  boost_wf,
  resamples = pokeFolds,
  grid = trees_grid,
  metrics = metric_set(roc_auc)
)      

autoplot(boosted_tune_res)
```


What do you observe?

**It seems that the model has the best performance when there are roughly 1100 trees**

What is the `roc_auc` of your best-performing boosted tree model on the folds? *Hint: Use `collect_metrics()` and `arrange()`.*

**The roc_auc of the best performing boosted tree model on the folds is 0.701**

```{r}
boostedROC <- arrange(collect_metrics(boosted_tune_res), desc(mean))["mean"][1,]
boostedROC

```

### Exercise 10

Display a table of the three ROC AUC values for your best-performing pruned tree, random forest, and boosted tree models. Which performed best on the folds? Select the best of the three and use `select_best()`, `finalize_workflow()`, and `fit()` to fit it to the *testing* set. 

**The random forest model performed the best on the folds**

```{r}
prunedROC <- arrange(collect_metrics(tune_res), desc(mean))["mean"][1,]
rfROC <- arrange(collect_metrics(rf_tune_res), desc(mean))["mean"][1,]

ROC <- c(prunedROC, rfROC, boostedROC)
type <- c("pruned", "random forest", "xgboosted")

rocTable <- rbind(type, ROC)
rocTable

best_params <- select_best(rf_tune_res)
rf_final <- finalize_workflow(rf_wf, best_params)
rf_final_fit <- fit(rf_final, data = pokeTest)
```

Print the AUC value of your best-performing model on the testing set. Print the ROC curves. Finally, create and visualize a confusion matrix heat map.

```{r echo = T, eval = T, show = T}
augment(rf_final_fit, new_data = pokeTest) %>%
  roc_curve(truth = type_1, estimate = c(".pred_Bug", ".pred_Fire" ,
 ".pred_Grass" , ".pred_Normal" , ".pred_Psychic" , ".pred_Water" )) %>%
  autoplot()

augment(rf_final_fit, new_data = pokeTest) %>%
  conf_mat(truth = type_1, estimate = .pred_class) %>%
  autoplot(type = "heatmap")
```

Which classes was your model most accurate at predicting? Which was it worst at?

**The model was the most accurate at predicting water and normal types. It was the worst at predicting grass and fire types.**

## For 231 Students

### Exercise 11

Using the `abalone.txt` data from previous assignments, fit and tune a random forest model to predict `age`. Use stratified cross-validation and select ranges for `mtry`, `min_n`, and `trees`. Present your results. What was the model's RMSE on your testing set?



```{r}
abData <- read_csv("data/abalone.csv")

abData$age <- abData$rings + 1.5

abSplit <- initial_split(abData, 
                         prop = 0.8,
                         strata = age)

abTrain <- training(abSplit)
abTest <- testing(abSplit)

abFolds <- vfold_cv(abTrain, 
                    v = 10,
                    strata = age)

abRecipe <- recipe(age ~ . , data = abTrain) %>%
  step_rm(rings) %>%
  step_dummy(all_nominal_predictors()) %>%
  step_interact(terms = ~ starts_with("type"):shucked_weight +
                  longest_shell:diameter + 
                  shucked_weight:shell_weight) %>% 
  step_normalize(all_predictors())


ab_rf_spec <- rand_forest() %>%
  set_engine("randomForest", importance = TRUE) %>% # can change to random forest if ranger doesnt work
  set_mode("regression")


abWf <- workflow() %>%
  add_model(ab_rf_spec %>% set_args(mtry = tune(), trees = tune(), min_n = tune())) %>%
  add_recipe(abRecipe)


ab_param_grid <- grid_regular(mtry(range = c(1,8)),
                           min_n(range = c(1,10)),
                           trees(range = c(10,300)), levels = 8)


test_grid <- grid_regular(mtry(range = c(1,2)),
                           min_n(range = c(1,2)),
                           trees(range = c(10,11)), levels = 1)

ab_rf_tune_res <- tune_grid(
  abWf, 
  resamples = abFolds, 
  grid = ab_param_grid, 
  metrics = metric_set(rmse),
  control = control_grid(verbose = F)
)

autoplot(ab_rf_tune_res)


best_params <- select_best(ab_rf_tune_res)
ab_rf_final <- finalize_workflow(abWf, best_params)
ab_rf_final_fit <- fit(ab_rf_final, data = abTrain)

ab_rf_final_fit%>%
  pull_workflow_fit()%>%
  vip()
```